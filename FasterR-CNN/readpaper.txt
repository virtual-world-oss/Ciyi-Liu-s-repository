Faster R-CNN:Towards Real-Time Object
Detection with Region Proposal Networks


摘要：在作者的构思中，将RPN与检测网络共享全图像卷积特征，由此来实现无成本的区域建议。
注意：最先进的目标检测网络依靠区域建议算法来假设目标的位置。
摘要重点部分翻译：
在本工作中，我们引入了一个区域提案网络( RPN )，该网络与检测网络共享全图像卷积特征，从而使得几乎不需要成本的区域提案。RPN是一个全卷积网络，它同时预测每个位置的对象边界和对象性得分。RPN接受端到端的培训，以生成高质量的区域提案，这些提案被Fast R- CNN用于检测。我们进一步将RPN和Fast R - CNN通过共享它们的卷积特征融合到一个单一的网络中- -利用最近流行的带有"注意"机制的神经网络术语，RPN组件告诉统一的网络在哪里查找。

INTRODUCTION
第一段：
主要说了目标检测是由区域推荐方法和基于区域的卷积神经网络的成功驱动的。
之前基于区域的卷积神经网络比较贵，但是由于一些技术的突破已经降低了成本，而且在不考虑区域建议所消耗的时间时，fast cnn已经基本上实现了实施速率，所以引出区域建议是一个瓶颈。

第二段：
指出了区域建议方法依赖于廉价的特征和经济的推断方案。
指出目前最流行的两个方案，
Selective search是最流行，但在CPU上每张图要2秒中。
Edge Boxes是对质量和速度的一个折中，但仍消耗了和检测网络相同的时间。

第三段：
这里指出了为什么不在GPU上重新实现区域推荐算法，作者给出的解释为：这样做忽略了下游的检测网络，结果错失了共享计算的机会。

第四段：
作者给出了自己的方案：测试时共享最先进的目标检测网络的卷积层。通过在测试时共享卷积，计算区域建议的边际成本很小。

第五段：
第五段理论上介绍了怎么在基于区域的检测网络的基础上构建RPN
在这些卷积特征之上，我们通过添加一些额外的卷积层来构建RPN，这些卷积层同时在规则网格上的每个位置上回归区域边界和目标分数。因此RPN是一种全卷积网络（FCN）[7]，可以针对生成检测区域建议的任务进行端到端的训练。

第六段：
作者介绍了自己的模型：
我们引入新的“锚”框作为多种尺度和长宽比的参考。我们的方案可以被认为是回归参考金字塔（图1，c），它避免了枚举多种尺度或长宽比的图像或滤波器。这个模型在使用单尺度图像进行训练和测试时表现良好，从而有利于运行速度。
就是图片可能由不同大小，而实现过程中引进锚框。
RPN旨在有效预测具有广泛尺度和长宽比的区域建议。

第七段：
为了将RPN与Fast R-CNN目标检测网络相结合，提出了一种新的训练方案。
在微调区域建议任务和微调目标检测之间进行交替，微调目标检测时保持区域建议固定。该方案收敛速度快，并产生两个任务之间共享卷积特征的统一网络。
什么是fine-tuning?
就是在现有的预训练网络上更改输入层重新训练网络，微调卷积网络的后两层

introduction的后三段主要记录了本次实验的成果和在各数据集上测试的效果。


二、相关工作
第一段：
简单介绍了目标建议算法

第二段（大段）：
在这一段中，作者再一次强调了目标检测的精度依赖于区域建议模块的性能。
在这一大段中介绍了两个基于深度网络的预测目标边界框的方法overfeat和multibox
在OverFeat方法[9]中，训练一个全连接层来预测假定单个目标定位任务的边界框坐标。然后将全连接层变成卷积层，用于检测多个类别的目标。
MultiBox方法[26]，[27]从网络中生成区域建议，网络最后的全连接层同时预测多个类别未知的边界框，并推广到OverFeat的“单边界框”方式。这些类别不可知的边界框被用作R-CNN的建议区域[5]。
MultiBox建议网络适用于单张裁剪图像或多张大型裁剪图像
另外，段末提了一下DeepMask方法，用于开发用于学习图像分割任务的建议区域


第三段：
再次将overfeat算法和fast r-cnn算法比较，指出了
Fast R-CNN[2]能够在共享的卷积特征上进行端到端的检测器训练，并显示出令人信服的准确性和速度。



三、原理介绍Δ
第一段：
从整体上介绍了作者采用的目标检测系统-Faster R-CNN，包括两个模块：1、提取区域的深度全卷积网络；2、提取区域的fast r-cnn检测器。
RPN通过神经网络“注意力”机制这一概念告诉Fast R-CNN模块在哪里寻找。
并从整体上介绍了：
在第3.1节中，我们介绍了区域建议网络的设计和属性。在第3.2节中，我们开发了用于训练具有共享特征的两个模块的算法。

3.1 区域建议网络
第一二段：
这两段概括了如何生成一个区域建议。
形式上，
以任意大小的图像作为输入，输出一组矩形的目标建议，每个建议都有一个目标得分。 
利用了两个模型：具有个可以共享的卷积层的Zeiler和Fergus模型（ZF）和具有13个可以共享的卷积层的Simonyan和Zisserman模型（VGG-16）
ΔΔΔ在第二段具体概括了生成区域建议的方式；
下面引入CSDN上的一个解释：
	• 该网络是对VGG-16最后一层输出的卷积特征图(conv feature map)进行处理。
	• 滑窗(sliding window):亦可看为卷积核，对图片所有区域进行处理。
	• Intermediate layer(256-d):中间层括号中的为其维度（ZF为256维，VGG为512维）。
	• Cls layer：边界框分类层，该层包含2k scores，输出2k个分数，对应是目标或不是目标的概率(下文中的Pi)。
	• Reg layer：边界框回归层，包含4k coordinates即K个边界框的中心坐标与宽高（x,y,w,h）(下文中的Ti).
	• K anchors boxes，相对于当前滑动窗口中心(anchors)的K个参考边界框，文中提及K为9。

第二段比较重要，这里先对几个小概念进行解释
在共享卷积层输出的卷积特征映射上滑动一个小网络：这个小网络可以看成一个卷积核
reg（边界框回归层）：用于定位边框的位置，用四个参数（x,y,w,h）
Cls（边界框分类层）：给出边框的分数，表示是目标的概率。
第二段所描述的具体实现：
每个滑动窗口区域被映射到一个低维特征（ZF为256维，VGG为512维，都伴随着ReLU[33]激活）。这个特征被输入到两个子全连接层——一个边界框回归层（reg）和一个边界框分类层（cls）。

3.11
第一段：
每个滑动窗口位置同时预测多个区域建议，每个位置可能建议的最大数目为k，
因此，reg层具有4k个输出，用于编码k个边界框的坐标，cls层输出2k个分数，用于估计每个建议是目标或不是目标的概率。
这k个区域建议就是文章中说的锚框。
对于大小为W×H（通常约为2400）的卷积特征映射，总共有WHk个锚框。

平移不变的锚框：
第一段主要介绍了平移不变这一特性：
如果在图像中平移目标，区域建议位置也应该平移，并且同样的函数应该能够在任一位置预测区域建议。
第二段与MultiBox方法做对比，指出了平移不变性减小了模型的大小。
在PASCAL VOC等小数据集上有更小的过拟合风险。

多尺度锚框作为回归参考
第一段：
第一段主要介绍了多尺度预测的两种流行方法
1、图像/特征金字塔：主要思想是对图像进行在多尺度上的缩放，针对每个尺度计算特征映射。
2、在特征映射上使用多尺度的滑动窗口。
使用不同的滤波器大小（例如5×7和7×5）分别对不同长宽比的模型进行训练。
第二种方法通常与第一种方法联合采用

第二段：
主要说了本文采用的方法锚框金字塔，
参照多尺度和长宽比的锚框来分类和回归边界框。它只依赖单一尺度的图像和特征映射，并使用单一尺寸的滤波器（特征映射上的滑动窗口）

第三段：
由于这种基于锚框的多尺度设计，我们可以简单地使用在单尺度图像上计算的卷积特征，Fast R-CNN检测器也是这样做的[2]。多尺度锚框设计是共享特征的关键组件，不需要额外的成本来处理尺度。
解释一下：
就是说虽然给出的区域建议是支持多尺度的，但是使用的是多尺度锚框，而不是对图像或滤波器进行尺度操作，这与Fast R-CNN的检测器是相通的，因此可以共享特征。


3.1.2损失函数
第一段：
这一段主要给出了为锚框分配二值类别标签的标准（是目标或不是目标：二值标签）。
我们给两种锚框分配一个正标签：（i）具有与实际边界框的重叠最高交并比（IoU）的锚框，或者（ii）具有与实际边界框的IoU重叠超过0.7的锚框。
对于所有的真实边界框，如果与锚框的IoU比率低于0.3，我们给这样的非正样本的锚框分配一个负标签。
注意：既不是正标签，也不是负标签的锚框不用于训练！

最后一段之前的几段：（主要是解析loss函数）：
损失函数如下图：


其中，i是小批量数据（可以看成滑动窗里的那些数据）中锚框的索引，pi是i是目标的预测概率。
如果锚框为正，则对应的真实标签p i ∗ ​的值为1，如果锚框为负，则为0。
p i ∗ L r e g项表示回归损失仅对于正锚框激活(p i ∗ = 1)，否则被禁用（p i ∗ = 0 ）。c l s和r e g层的输出分别由{p i​}和{t i​}组成。
下面是对两个L的解释


另外，公式中Ncls和Nreg用于归一化，Ncls取256，Nreg取2400
公式中lamda用于平衡权重，取10
实验证明，归一化不是必须的，可以简化

对于边界框回归，我们采用[5]中的4个参数化的坐标：

其中，x，y，w和h表示边界框的中心坐标及其宽和高。
变量x，x a​和x ∗分别表示预测边界框、锚盒和真实边界框（y,w ,h同样）。这可以被认为是从锚盒到邻近的真实边界框的边框回归。

最后一段：
与RoI算法进行了比较

3.1.3训练RPN
RPN可以通过反向传播和随机梯度下降（SGD）进行端到端训练
本文中，使用多步训练法。
在图像中随机采样256个锚框，计算一个小批量数据的损失函数，这样正负锚框比可以取1：1.如果图像中正样本少于128个，使用负样本填充小批量数据

初始化新层时，从标准方差为0.01的零均值高斯分布中提取权重来随机初始化。
共享卷积层通过预训练的ImageNet分类模型来初始化。



3.2
RPN和Fast R-CNN共享特征

该部分主要介绍了三种可能的用来训练具有特征共享网络的算法：
1、交替训练
	首先训练RPN，并使用这些区域建议来训练Fast R-CNN。由Fast R-CNN微调的网络然后被用于初始化RPN，并且重复这个过程。
2、近似联合训练
	在这个方案中，将RPN和Fast R-CNN网络在训练期间合并成了一个网络，每次SGD迭代中，前向传递生成区域建议，
	在训练Fast R-CNN检测器时将这看作是固定的、预计算的区域建议。反向传播像往常一样进行，其中对于共享层，组合来自RPN损失和Fast R-CNN损失的反向传播信号。 
	这个方法忽略了训练识别网络时，将边界框的坐标作为参数输入给Fast R-CNN网络，所以只能近似训练。
	在源码中，作者给出了基于这个算法的求解器。
	但是使用这个方法训练时间得以缩短。
3、非近似的联合训练
	这个方法是对2的改进，需要设定一个关于边界框坐标可微分的ROI池化层，作者在文中并没有给出详细说明。
	
注：在作者的实验中，训练采用的是第一种方法，交替训练，也就是交替独立的训练各部分，最后再合并权重，这是最好理解和实现的一种方法，但其实在查询资料后发现联合训练，也就是2、3种方法效果更好

下面列出作者的训练方法：作者将其称为四步交替训练
在第一步中，我们按照3.1.3节的描述训练RPN。该网络使用ImageNet的预训练模型进行初始化，并针对区域建议任务进行了端到端的微调。在第二步中，我们使用由第一步RPN生成的区域建议，由Fast R-CNN训练单独的检测网络。该检测网络也由ImageNet的预训练模型进行初始化。此时两个网络不共享卷积层。在第三步中，我们使用检测器网络来初始化RPN训练，但是我们固定共享的卷积层，只对RPN特有的层进行微调。现在这两个网络共享卷积层。最后，保持共享的卷积层固定，我们对Fast R-CNN独有的层进行微调。因此，两个网络共享相同的卷积层并形成统一的网络。类似的交替训练可以运行更多次迭代，但是我们只观察到可以忽略的改进。
简而言之：第一步，用预训练模型初始化RPN，端对端训练并微调，后假设训练好了，生成一组区域建议，用生成的区域建议结合Fast R-CNN训练识别网络。识别网络也是由预训练模型初始化。
之后用检测（识别）网络初始化RPN，再次进行训练，固定共享卷积层不变，只微调特有层。
最后，
最后，保持共享的卷积层固定，我们对Fast R-CNN独有的层进行微调。因此，两个网络共享相同的卷积层并形成统一的网络。类似的交替训练可以运行更多次迭代。但是多次迭代效果甚微。

3.3实现细节
我注意到的一些细节：
重新放缩了图像，使得它们的短边为600像素。
在重新缩放的图像上，在ZF和VGG网络的最后卷积层上的总步长为16个像素。
为了速度与精度的折中，没有才有图像金字塔（而是基于回归参考金字塔（锚框机制））
对于一个典型的1000*600的图片，总共将会有大约20000 （ ≈ 60 × 40 × 9 ） 个锚框。跨界锚框被忽略，每张图像约有6000 个锚框用于训练。
为了减少冗余，我们在建议区域根据他们的c l s cls分数采取非极大值抑制（NMS）。我们将NMS的IoU阈值固定为0.7，这就给每张图像留下了大约2000个建议区域。


