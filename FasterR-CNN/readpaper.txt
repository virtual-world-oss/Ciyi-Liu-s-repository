Faster R-CNN:Towards Real-Time Object
Detection with Region Proposal Networks


摘要：在作者的构思中，将RPN与检测网络共享全图像卷积特征，由此来实现无成本的区域建议。
注意：最先进的目标检测网络依靠区域建议算法来假设目标的位置。
摘要重点部分翻译：
在本工作中，我们引入了一个区域提案网络( RPN )，该网络与检测网络共享全图像卷积特征，从而使得几乎不需要成本的区域提案。RPN是一个全卷积网络，它同时预测每个位置的对象边界和对象性得分。RPN接受端到端的培训，以生成高质量的区域提案，这些提案被Fast R- CNN用于检测。我们进一步将RPN和Fast R - CNN通过共享它们的卷积特征融合到一个单一的网络中- -利用最近流行的带有"注意"机制的神经网络术语，RPN组件告诉统一的网络在哪里查找。

INTRODUCTION
第一段：
主要说了目标检测是由区域推荐方法和基于区域的卷积神经网络的成功驱动的。
之前基于区域的卷积神经网络比较贵，但是由于一些技术的突破已经降低了成本，而且在不考虑区域建议所消耗的时间时，fast cnn已经基本上实现了实施速率，所以引出区域建议是一个瓶颈。

第二段：
指出了区域建议方法依赖于廉价的特征和经济的推断方案。
指出目前最流行的两个方案，
Selective search是最流行，但在CPU上每张图要2秒中。
Edge Boxes是对质量和速度的一个折中，但仍消耗了和检测网络相同的时间。

第三段：
这里指出了为什么不在GPU上重新实现区域推荐算法，作者给出的解释为：这样做忽略了下游的检测网络，结果错失了共享计算的机会。

第四段：
作者给出了自己的方案：测试时共享最先进的目标检测网络的卷积层。通过在测试时共享卷积，计算区域建议的边际成本很小。

第五段：
第五段理论上介绍了怎么在基于区域的检测网络的基础上构建RPN
在这些卷积特征之上，我们通过添加一些额外的卷积层来构建RPN，这些卷积层同时在规则网格上的每个位置上回归区域边界和目标分数。因此RPN是一种全卷积网络（FCN）[7]，可以针对生成检测区域建议的任务进行端到端的训练。

第六段：
作者介绍了自己的模型：
我们引入新的“锚”框作为多种尺度和长宽比的参考。我们的方案可以被认为是回归参考金字塔（图1，c），它避免了枚举多种尺度或长宽比的图像或滤波器。这个模型在使用单尺度图像进行训练和测试时表现良好，从而有利于运行速度。
就是图片可能由不同大小，而实现过程中引进锚框。
RPN旨在有效预测具有广泛尺度和长宽比的区域建议。

第七段：
为了将RPN与Fast R-CNN目标检测网络相结合，提出了一种新的训练方案。
在微调区域建议任务和微调目标检测之间进行交替，微调目标检测时保持区域建议固定。该方案收敛速度快，并产生两个任务之间共享卷积特征的统一网络。
什么是fine-tuning?
就是在现有的预训练网络上更改输入层重新训练网络，微调卷积网络的后两层

introduction的后三段主要记录了本次实验的成果和在各数据集上测试的效果。


二、相关工作
第一段：
简单介绍了目标建议算法

第二段（大段）：
在这一段中，作者再一次强调了目标检测的精度依赖于区域建议模块的性能。
在这一大段中介绍了两个基于深度网络的预测目标边界框的方法overfeat和multibox
在OverFeat方法[9]中，训练一个全连接层来预测假定单个目标定位任务的边界框坐标。然后将全连接层变成卷积层，用于检测多个类别的目标。
MultiBox方法[26]，[27]从网络中生成区域建议，网络最后的全连接层同时预测多个类别未知的边界框，并推广到OverFeat的“单边界框”方式。这些类别不可知的边界框被用作R-CNN的建议区域[5]。
MultiBox建议网络适用于单张裁剪图像或多张大型裁剪图像
另外，段末提了一下DeepMask方法，用于开发用于学习图像分割任务的建议区域


第三段：
再次将overfeat算法和fast r-cnn算法比较，指出了
Fast R-CNN[2]能够在共享的卷积特征上进行端到端的检测器训练，并显示出令人信服的准确性和速度。



三、原理介绍Δ
第一段：
从整体上介绍了作者采用的目标检测系统-Faster R-CNN，包括两个模块：1、提取区域的深度全卷积网络；2、提取区域的fast r-cnn检测器。
RPN通过神经网络“注意力”机制这一概念告诉Fast R-CNN模块在哪里寻找。
并从整体上介绍了：
在第3.1节中，我们介绍了区域建议网络的设计和属性。在第3.2节中，我们开发了用于训练具有共享特征的两个模块的算法。

3.1 区域建议网络
第一二段：
这两段概括了如何生成一个区域建议。
形式上，
以任意大小的图像作为输入，输出一组矩形的目标建议，每个建议都有一个目标得分。 
利用了两个模型：具有个可以共享的卷积层的Zeiler和Fergus模型（ZF）和具有13个可以共享的卷积层的Simonyan和Zisserman模型（VGG-16）
ΔΔΔ在第二段具体概括了生成区域建议的方式；
下面引入CSDN上的一个解释：
	• 该网络是对VGG-16最后一层输出的卷积特征图(conv feature map)进行处理。
	• 滑窗(sliding window):亦可看为卷积核，对图片所有区域进行处理。
	• Intermediate layer(256-d):中间层括号中的为其维度（ZF为256维，VGG为512维）。
	• Cls layer：边界框分类层，该层包含2k scores，输出2k个分数，对应是目标或不是目标的概率(下文中的Pi)。
	• Reg layer：边界框回归层，包含4k coordinates即K个边界框的中心坐标与宽高（x,y,w,h）(下文中的Ti).
	• K anchors boxes，相对于当前滑动窗口中心(anchors)的K个参考边界框，文中提及K为9。

第二段比较重要，这里先对几个小概念进行解释
在共享卷积层输出的卷积特征映射上滑动一个小网络：这个小网络可以看成一个卷积核
reg（边界框回归层）：用于定位边框的位置，用四个参数（x,y,w,h）
Cls（边界框分类层）：给出边框的分数，表示是目标的概率。
第二段所描述的具体实现：
每个滑动窗口区域被映射到一个低维特征（ZF为256维，VGG为512维，都伴随着ReLU[33]激活）。这个特征被输入到两个子全连接层——一个边界框回归层（reg）和一个边界框分类层（cls）。


